{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from scipy.sparse import hstack\n",
        "import joblib\n",
        "\n",
        "\n",
        "print(\"[1/5] Loading dataset...\")\n",
        "\n",
        "DATASET_PATH = '/content/Modified_SQL_Dataset.csv'\n",
        "df = pd.read_csv(DATASET_PATH)\n",
        "\n",
        "print(f\"âœ“ Dataset loaded: {len(df)} samples\")\n",
        "print(f\"  Normal: {(df['Label']==0).sum()}\")\n",
        "print(f\"  Malicious: {(df['Label']==1).sum()}\")\n",
        "\n",
        "print(\"\\n[2/5] Extracting features...\")\n",
        "\n",
        "df['length'] = df['Query'].apply(len)\n",
        "df['special_chars'] = df['Query'].apply(lambda x: sum(1 for c in x if not c.isalnum() and not c.isspace()))\n",
        "df['single_quotes'] = df['Query'].apply(lambda x: x.count(\"'\"))\n",
        "df['equals_count'] = df['Query'].apply(lambda x: x.count('='))\n",
        "df['dash_count'] = df['Query'].apply(lambda x: x.count('-'))\n",
        "\n",
        "print(\"âœ“ Features extracted\")\n",
        "\n",
        "print(\"\\n[3/5] Splitting data...\")\n",
        "\n",
        "X = df['Query']\n",
        "y = df['Label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"âœ“ Train: {len(X_train)} | Test: {len(X_test)}\")\n",
        "\n",
        "print(\"\\n[4/5] Creating TF-IDF features...\")\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    ngram_range=(1, 3),\n",
        "    analyzer='char',\n",
        "    lowercase=True\n",
        ")\n",
        "\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "numerical_features = df[['length', 'special_chars', 'single_quotes',\n",
        "                          'equals_count', 'dash_count']].values\n",
        "\n",
        "X_train_numerical = numerical_features[X_train.index]\n",
        "X_test_numerical = numerical_features[X_test.index]\n",
        "\n",
        "X_train_combined = hstack([X_train_vec, X_train_numerical])\n",
        "X_test_combined = hstack([X_test_vec, X_test_numerical])\n",
        "\n",
        "print(\"âœ“ Features combined\")\n",
        "\n",
        "print(\"\\n[5/5] Training model...\")\n",
        "\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=30,\n",
        "    min_samples_split=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "\n",
        "model.fit(X_train_combined, y_train)\n",
        "y_pred = model.predict(X_test_combined)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"âœ“ Training completed!\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"EVALUATION RESULTS\")\n",
        "print('='*60)\n",
        "print(f\"\\nAccuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Normal', 'Malicious']))\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"SAVING MODEL\")\n",
        "print('='*60)\n",
        "\n",
        "model_package = {\n",
        "    'model': model,\n",
        "    'vectorizer': vectorizer,\n",
        "    'version': '1.0',\n",
        "    'accuracy': accuracy\n",
        "}\n",
        "\n",
        "joblib.dump(model_package, 'sqli_detector.pkl')\n",
        "\n",
        "print(\"Model saved: sqli_detector.pkl\")\n",
        "print(\"TRAINING COMPLETED SUCCESSFULLY!\")\n",
        "print(f\"\\nModel Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"Saved file: sqli_detector.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e8ajhAh57xb",
        "outputId": "d42c6517-339f-4cfe-cf7b-745d0632fdca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/5] Loading dataset...\n",
            "âœ“ Dataset loaded: 30919 samples\n",
            "  Normal: 19537\n",
            "  Malicious: 11382\n",
            "\n",
            "[2/5] Extracting features...\n",
            "âœ“ Features extracted\n",
            "\n",
            "[3/5] Splitting data...\n",
            "âœ“ Train: 24735 | Test: 6184\n",
            "\n",
            "[4/5] Creating TF-IDF features...\n",
            "âœ“ Features combined\n",
            "\n",
            "[5/5] Training model...\n",
            "âœ“ Training completed!\n",
            "\n",
            "============================================================\n",
            "EVALUATION RESULTS\n",
            "============================================================\n",
            "\n",
            "Accuracy: 0.9956 (99.56%)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.99      1.00      1.00      3908\n",
            "   Malicious       1.00      0.99      0.99      2276\n",
            "\n",
            "    accuracy                           1.00      6184\n",
            "   macro avg       1.00      0.99      1.00      6184\n",
            "weighted avg       1.00      1.00      1.00      6184\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3908    0]\n",
            " [  27 2249]]\n",
            "\n",
            "============================================================\n",
            "SAVING MODEL\n",
            "============================================================\n",
            "Model saved: sqli_detector.pkl\n",
            "TRAINING COMPLETED SUCCESSFULLY!\n",
            "\n",
            "Model Accuracy: 99.56%\n",
            "Saved file: sqli_detector.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "from scipy.sparse import hstack\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    model_package = joblib.load('sqli_detector.pkl')\n",
        "    model = model_package['model']\n",
        "    vectorizer = model_package['vectorizer']\n",
        "    print(f\"Model loaded (Accuracy: {model_package['accuracy']*100:.2f}%)\\n\")\n",
        "except FileNotFoundError:\n",
        "    print(\"ERROR: Model file 'sqli_detector.pkl' not found!\")\n",
        "    sys.exit(1)\n",
        "\n",
        "def detect(query):\n",
        "    query_vec = vectorizer.transform([query])\n",
        "\n",
        "    features = [[\n",
        "        len(query),\n",
        "        sum(1 for c in query if not c.isalnum() and not c.isspace()),\n",
        "        query.count(\"'\"),\n",
        "        query.count('='),\n",
        "        query.count('-')\n",
        "    ]]\n",
        "\n",
        "    query_combined = hstack([query_vec, features])\n",
        "\n",
        "    prediction = model.predict(query_combined)[0]\n",
        "    proba = model.predict_proba(query_combined)[0]\n",
        "\n",
        "    return {\n",
        "        'is_malicious': bool(prediction == 1),\n",
        "        'score': proba[1],\n",
        "        'safe_score': proba[0]\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"SQL Injection Detector\")\n",
        "print(\"Enter queries to test (type 'exit' to quit)\\n\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        query = input(\"Query: \").strip()\n",
        "\n",
        "        if query.lower() in ['exit', 'quit', 'q']:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        if not query:\n",
        "            continue\n",
        "\n",
        "        result = detect(query)\n",
        "\n",
        "        if result['is_malicious']:\n",
        "            print(f\"  ðŸš¨ MALICIOUS ({result['score']*100:.2f}%)\")\n",
        "        else:\n",
        "            print(f\"  âœ… SAFE ({result['safe_score']*100:.2f}%)\")\n",
        "        print()\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\nGoodbye!\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OopFoMvS6Tl6",
        "outputId": "ebe20292-50f6-4cc4-c409-3ba50c84e1d7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded (Accuracy: 99.56%)\n",
            "\n",
            "SQL Injection Detector\n",
            "Enter queries to test (type 'exit' to quit)\n",
            "\n",
            "Query: ' oR 1=1 --\n",
            "  ðŸš¨ MALICIOUS (98.99%)\n",
            "\n",
            "\n",
            "\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ]
}